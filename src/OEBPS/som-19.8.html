<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Society of Mind</title>
    <link rel="stylesheet" href="stylesheet.css" type="text/css" />


</head>
<body>
<h2>19.8 generalizing</h2>

    <p>
      We&#39;re always learning from experience by seeing some examples
      and then applying them to situations that we&#39;ve never seen
      before. A single frightening growl or bark may lead a baby to fear
      all dogs of similar size &mdash; or, even, animals of every
      kind. How do we make generalizations from fragmentary bits of
      evidence? A dog of mine was once hit by a car, and it never went
      down the same street again &mdash; but it never stopped chasing cars
      on other streets.</p>

    <p>
      Philosophers of every period have tried to generalize about how we
      learn so much from our experiences. They have proposed many theories
      about this, using names
      like <em>abstraction,</em> <em>induction,</em>
      <em>abduction,</em> and so forth. But no one has found a way to make
      consistently correct generalizations &mdash; presumably because no
      such foolproof scheme exists, and whatever we <em>learn</em> may
      turn out to be wrong. In any case, we humans do not learn in accord
      with any fixed and constant set of principles; instead, we
      accumulate societies of learning-schemes that differ both in quality
      and kind.</p>

    <p>
      We&#39;ve already seen several ways to generalize. One way is to
      construct uniframes by formulating descriptions that suppress
      details we regard as insignificant. A related idea is built into our
      concept of a
      <em>level-band.</em> Yet another scheme is implicit in the concept
      of a polyneme, which tries to guess the character of things by
      combining expectations based upon some independent properties. In
      any case, there is an intimate relationship between how
      we <em>represent</em> what we already know and the generalizations
      that will seem most plausible. For example, when we first proposed
      a <em>recognizer</em> for a chair, we composed it from the polynemes
      for several already familiar ideas, namely seats, legs, and
      backs. We gave these features certain weights.</p>

    <p>
      If we changed the values of those evidence weights, this would
      produce new recognizer-agents. For example, with a negative weight
      for <em>back,</em> the new agent would reject chairs but would
      accept benches, stools, or tables. If all the weights were increased
      (but the required total were kept the same), the new recognizer
      would accept a wider class of furniture or furniture with more parts
      hidden from view &mdash; as well as other objects that weren&#39;t
      furniture at all.</p>

    <p>
      Why would there be any substantial likelihood that such variations
      would produce useful recognizers? That would be unlikely indeed, if
      we assembled new recognizers by combining old ones selected at
      random. But there is a much better chance for usefulness if each new
      recognizer is made by combining signals from agents that have
      already proven themselves useful in related contexts. As Douglas
      Hofstadter has explained:</p>

    <p>
      Making variations on a theme is the crux of creativity. But it is
      not some magical, mysterious process that occurs when two
      indivisible concepts collide; it is a consequence of the
      divisibility of concepts into already significant subconceptual
      elements.</p>
</body>
</html>
